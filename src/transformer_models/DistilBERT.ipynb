{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1765060127844,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "malwwWR8AeEP"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "find /content/drive/MyDrive -maxdepth 4 -type f -name 'fever_tokenized_distilbert.zip' -print || true\n",
    "ls -lh /content/drive/MyDrive/fever_tokenized_distilbert.zip || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1765060127855,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "BxvYZjhAAd5v"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "TS=$(date +%s)\n",
    "BASE=\"/content/drive/MyDrive\"\n",
    "ZIP=\"$BASE/fever_tokenized_distilbert.zip\"\n",
    "DEST=\"$BASE\"\n",
    "\n",
    "if [ ! -f \"$ZIP\" ]; then\n",
    "  echo \"Zip not found at $ZIP. Upload it to My Drive and re-run this cell.\"\n",
    "else\n",
    "  echo \"Backing up possible existing top-level dataset files...\"\n",
    "  CONFLICTS=(\"dataset_dict.json\" \"train\" \"validation\" \"test\" \"fever_tokenized_distilbert\")\n",
    "  for name in \"${CONFLICTS[@]}\"; do\n",
    "    if [ -e \"$DEST/$name\" ]; then\n",
    "      echo \"Backing up $name -> ${name}.bak.$TS\"\n",
    "      mv \"$DEST/$name\" \"$DEST/${name}.bak.$TS\"\n",
    "    fi\n",
    "  done\n",
    "\n",
    "  echo \"Unzipping (overwrite) $ZIP -> $DEST\"\n",
    "  unzip -o \"$ZIP\" -d \"$DEST\"\n",
    "  echo \"Unzip finished. Top-level listing:\"\n",
    "  ls -la \"$DEST\" | sed -n '1,200p'\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1765060127863,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "nqhh_2g4AdtR"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p /content/drive/MyDrive/fever_tokenized_distilbert\n",
    "\n",
    "# move expected parts into folder (silently ignore missing)\n",
    "mv /content/drive/MyDrive/dataset_dict.json /content/drive/MyDrive/fever_tokenized_distilbert/ 2>/dev/null || true\n",
    "mv /content/drive/MyDrive/train /content/drive/MyDrive/fever_tokenized_distilbert/ 2>/dev/null || true\n",
    "mv /content/drive/MyDrive/validation /content/drive/MyDrive/fever_tokenized_distilbert/ 2>/dev/null || true\n",
    "mv /content/drive/MyDrive/test /content/drive/MyDrive/fever_tokenized_distilbert/ 2>/dev/null || true\n",
    "\n",
    "echo \"Contents of tokenized folder now:\"\n",
    "ls -la /content/drive/MyDrive/fever_tokenized_distilbert | sed -n '1,200p' || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1765060127875,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "RsIegRXaAtQY"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "git clone https://github.com/kvj-085/NLP_project.git /content/repo || true\n",
    "ls -la /content/repo | sed -n '1,200p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1765060127882,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "kjhmX_vbAtGG"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "repo_dir = \"/content/repo\"   \n",
    "\n",
    "if not os.path.exists(repo_dir):\n",
    "    raise SystemExit(f\"Repo not found at {repo_dir} — run the clone/copy step first or update repo_dir\")\n",
    "\n",
    "# add repo to path and change cwd\n",
    "if repo_dir not in sys.path:\n",
    "    sys.path.insert(0, repo_dir)\n",
    "os.chdir(repo_dir)\n",
    "print(\"cwd:\", os.getcwd())\n",
    "print(\"repo top-level:\", os.listdir('.')[:200])\n",
    "print(\"src present?:\", os.path.exists('src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1765060127894,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "1w1EAm4pA2oV"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install -q --no-deps transformers datasets tokenizers huggingface-hub safetensors fsspec scikit-learn accelerate\n",
    "echo \"Top-level packages installed (no-deps). If a specific import fails, install that single package.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1765060127903,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "M22VXl22A7Wl"
   },
   "outputs": [],
   "source": [
    "import transformers, datasets, torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print(\"transformers\", transformers.__version__)\n",
    "print(\"datasets\", datasets.__version__)\n",
    "print(\"torch\", torch.__version__, \"cuda available:\", torch.cuda.is_available())\n",
    "!nvidia-smi || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1765060127908,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "jpocJG1CA9oq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_from_disk\n",
    "\n",
    "tokenized_path = '/content/drive/MyDrive/fever_tokenized_distilbert'\n",
    "print('exists:', os.path.exists(tokenized_path))\n",
    "if os.path.exists(tokenized_path):\n",
    "    ds = load_from_disk(tokenized_path)\n",
    "    print({split: len(ds[split]) for split in ds})\n",
    "    print('train columns:', ds['train'].column_names)\n",
    "    if 'input_ids' in ds['train'].column_names:\n",
    "        print('sample input_ids len:', len(ds['train'][0]['input_ids']))\n",
    "else:\n",
    "    print('Tokenized dataset not found at', tokenized_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1765060127912,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "SirZI3z8BBRa"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from src.models import train as train_module\n",
    "    print(\"Imported src.models.train OK —\", train_module.__file__)\n",
    "except Exception as e:\n",
    "    print(\"Import failed:\", type(e).__name__, e)\n",
    "    import traceback; traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1765060127929,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "fO6qTmKmDv5k"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "print('WANDB_MODE=', os.environ.get('WANDB_MODE'))\n",
    "print('WANDB_DISABLED=', os.environ.get('WANDB_DISABLED'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "aborted",
     "timestamp": 1765060127935,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "qbu_H84LHESW"
   },
   "outputs": [],
   "source": [
    "from src.models.train import run_training\n",
    "res = run_training(\n",
    "    processed_data_dir='/content/drive/MyDrive/fever_tokenized_distilbert',\n",
    "    model_name='distilbert-base-uncased',\n",
    "    output_dir='/content/drive/MyDrive/outputs/finetune_test',\n",
    "    epochs=0,\n",
    "    batch_size=8,\n",
    "    max_length=128,\n",
    "    save_tokenized=False,\n",
    "    gradient_accumulation_steps=1,\n",
    "    fp16=False\n",
    ")\n",
    "print(\"Dry-run returned:\", type(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "aborted",
     "timestamp": 1765060127940,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "VJH-K4xjBGdc"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi --query-gpu=index,name,memory.total,memory.free --format=csv,noheader,nounits || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1765060127945,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "jgIR0E61KFqH"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from src.models.train import run_training\n",
    "\n",
    "processed_data_dir = '/content/drive/MyDrive/fever_tokenized_distilbert'\n",
    "output_dir = '/content/drive/MyDrive/outputs/finetune_distilbert'\n",
    "\n",
    "print(\"Starting training: model=distilbert-base-uncased, max_length=128\")\n",
    "start = time.time()\n",
    "try:\n",
    "    trainer, tokenized = run_training(\n",
    "        processed_data_dir=processed_data_dir,\n",
    "        model_name='distilbert-base-uncased',\n",
    "        output_dir=output_dir,\n",
    "        num_labels=3,\n",
    "        epochs=3,\n",
    "        batch_size=16,                      \n",
    "        max_length=128,\n",
    "        save_tokenized=False,\n",
    "        gradient_accumulation_steps=2,       # effective batch = 16*2 = 32\n",
    "        fp16=True\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"Training finished in {elapsed/60:.1f} minutes. Check checkpoints in: {output_dir}\")\n",
    "except RuntimeError as e:\n",
    "    # catch common CUDA OOM errors and give fallback advice\n",
    "    msg = str(e)\n",
    "    print(\"Training failed with RuntimeError:\", msg)\n",
    "    if 'out of memory' in msg.lower() or 'cuda' in msg.lower():\n",
    "        print(\"\\nCUDA OOM detected. Recommended fallback options:\")\n",
    "        print(\"- Reduce per-device `batch_size` (e.g. 8) and increase `gradient_accumulation_steps` (e.g. 4).\")\n",
    "        print(\"- Or try batch_size=8, gradient_accumulation_steps=4 (effective batch 32).\")\n",
    "        print(\"- After adjusting, restart the runtime and re-run the training cell.\")\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# show saved outputs (if any)\n",
    "print(\"\\nDrive outputs (top-level):\")\n",
    "!ls -la /content/drive/MyDrive/outputs | sed -n '1,200p' || true\n",
    "print(\"\\nCheckpoint folder listing (if exists):\")\n",
    "!ls -la \"{output_dir}\" | sed -n '1,200p' || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1765060127955,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "nZtFFzfKRAET"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Quick sanity: show saved checkpoints\n",
    "ls -la /content/drive/MyDrive/outputs/finetune_distilbert | sed -n '1,200p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU evaluation sometimes crashes with CUDA device-side asserts if there’s even a small data or label mismatch. Running evaluation on CPU avoids these crashes because CPUs handle errors safely without killing the entire process. It is slower, but much more stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1765060127969,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "ttA2hD6IUVnZ"
   },
   "outputs": [],
   "source": [
    "# Manual CPU-only inference (no Trainer) — avoids CUDA device-side asserts\n",
    "import os, glob, numpy as np, pandas as pd, torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import load_from_disk\n",
    "\n",
    "tokenized_path = '/content/drive/MyDrive/fever_tokenized_distilbert'\n",
    "outdir = '/content/drive/MyDrive/outputs/finetune_distilbert'\n",
    "base_model_name = 'distilbert-base-uncased'\n",
    "batch_size = 64\n",
    "\n",
    "# pick checkpoint\n",
    "ckpts = sorted(glob.glob(os.path.join(outdir, \"checkpoint-*\")), key=os.path.getmtime)\n",
    "if not ckpts:\n",
    "    raise SystemExit(\"No checkpoints found\")\n",
    "best_ckpt = ckpts[-1]\n",
    "print(\"Using checkpoint:\", best_ckpt)\n",
    "print(\"Checkpoint files:\", os.listdir(best_ckpt))\n",
    "\n",
    "# load dataset\n",
    "ds = load_from_disk(tokenized_path)\n",
    "print(\"Splits:\", {k: len(v) for k,v in ds.items()})\n",
    "print(\"Validation columns:\", ds['validation'].column_names)\n",
    "print(\"Test columns:\", ds['test'].column_names)\n",
    "\n",
    "# Load tokenizer (fallback to Hub) and model (force CPU)\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(best_ckpt, local_files_only=True)\n",
    "    print(\"Loaded tokenizer from checkpoint (local).\")\n",
    "except Exception as e:\n",
    "    print(\"Checkpoint tokenizer load failed:\", repr(e))\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "    print(\"Loaded tokenizer from Hub:\", base_model_name)\n",
    "\n",
    "# Load model to CPU explicitly\n",
    "model = AutoModelForSequenceClassification.from_pretrained(best_ckpt, local_files_only=True)\n",
    "model.to('cpu')\n",
    "model.eval()\n",
    "print(\"Model num_labels:\", model.config.num_labels)\n",
    "\n",
    "# Helper to run inference on a split using DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def infer_split(split, split_name, model, batch_size=64, outdir=outdir):\n",
    "    # determine which input fields exist\n",
    "    input_fields = [f for f in ('input_ids','attention_mask','token_type_ids') if f in split.column_names]\n",
    "    label_field = None\n",
    "    for cand in ('label','labels'):\n",
    "        if cand in split.column_names:\n",
    "            label_field = cand\n",
    "            break\n",
    "\n",
    "    # set dataset format for torch\n",
    "    fmt_cols = input_fields + ([label_field] if label_field else [])\n",
    "    split.set_format(type='torch', columns=fmt_cols)\n",
    "    dl = DataLoader(split, batch_size=batch_size)\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            # move inputs to CPU (they are already torch tensors)\n",
    "            inputs = {k: batch[k].to('cpu') for k in input_fields}\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "            all_preds.extend(preds.tolist())\n",
    "            if label_field:\n",
    "                all_labels.extend(batch[label_field].cpu().numpy().tolist())\n",
    "\n",
    "    # Save CSV\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    df = pd.DataFrame({\n",
    "        \"idx\": np.arange(len(all_preds)),\n",
    "        \"prediction\": all_preds,\n",
    "        \"label\": (all_labels if len(all_labels) == len(all_preds) else [-1]*len(all_preds))\n",
    "    })\n",
    "    csv_path = os.path.join(outdir, f\"predictions_{split_name}.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved {split_name} predictions to: {csv_path}\")\n",
    "\n",
    "    return np.array(all_preds), (np.array(all_labels) if all_labels else None)\n",
    "\n",
    "# Run validation (compute metrics)\n",
    "val_preds, val_labels = infer_split(ds['validation'], \"validation\", model, batch_size=batch_size)\n",
    "if val_labels is None:\n",
    "    print(\"No validation labels found: cannot compute metrics.\")\n",
    "else:\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    acc = accuracy_score(val_labels, val_preds)\n",
    "    macro_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "    print(f\"Validation — accuracy: {acc:.6f}, macro_f1: {macro_f1:.6f}\")\n",
    "\n",
    "# Run test (save predictions). If test labels are invalid (e.g., -1) we skip metrics.\n",
    "test_labels_arr = np.array(ds['test']['label'])\n",
    "print(\"Test label min,max:\", test_labels_arr.min(), test_labels_arr.max())\n",
    "test_preds, test_labels = infer_split(ds['test'], \"test\", model, batch_size=batch_size)\n",
    "\n",
    "if test_labels is not None and (test_labels.min() >= 0 and test_labels.max() < model.config.num_labels):\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    acc = accuracy_score(test_labels, test_preds)\n",
    "    macro_f1 = f1_score(test_labels, test_preds, average='macro')\n",
    "    print(f\"Test — accuracy: {acc:.6f}, macro_f1: {macro_f1:.6f}\")\n",
    "else:\n",
    "    print(\"Test labels invalid for metric computation (likely -1); metrics skipped. Predictions saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1765060127973,
     "user": {
      "displayName": "Veera Jeeshitha Kolla",
      "userId": "15433795813484295271"
     },
     "user_tz": 300
    },
    "id": "QiX7eSgzRXg6"
   },
   "outputs": [],
   "source": [
    "final_save = \"/content/drive/MyDrive/outputs/finetune_distilbert/final_model\"\n",
    "import os\n",
    "os.makedirs(final_save, exist_ok=True)\n",
    "\n",
    "# save model (try safetensors when available)\n",
    "try:\n",
    "    # newer transformers supports safe_serialization flag\n",
    "    model.save_pretrained(final_save, safe_serialization=True)\n",
    "    print(\"Model saved (safetensors) ->\", final_save)\n",
    "except TypeError:\n",
    "    # fallback if flag unsupported\n",
    "    model.save_pretrained(final_save)\n",
    "    print(\"Model saved (pytorch) ->\", final_save)\n",
    "\n",
    "# save tokenizer\n",
    "tokenizer.save_pretrained(final_save)\n",
    "print(\"Tokenizer saved ->\", final_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== predictions_validation.csv ===\n",
      "Accuracy: 0.868537\n",
      "Macro F1: 0.866913\n",
      "\n",
      "Confusion Matrix:\n",
      "           Predicted\n",
      "                 0      1      2\n",
      "Actual\n",
      "       0     6094    572      0\n",
      "       1     2054   4612      0\n",
      "       2        3      0   6663\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "base_dir = \"C:/Users/jeesh/Desktop/NLP proj/outputs/DistilBERT\"\n",
    "files = [\"predictions_validation.csv\"] \n",
    "\n",
    "for fname in files:\n",
    "    path = os.path.join(base_dir, fname)\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Missing: {path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    if not {\"label\", \"prediction\"}.issubset(df.columns):\n",
    "        print(f\"{fname} missing required columns 'label' and 'prediction'.\")\n",
    "        continue\n",
    "\n",
    "    y_true = df[\"label\"].values\n",
    "    y_pred = df[\"prediction\"].values\n",
    "    \n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    labels_sorted = sorted(set(y_true) | set(y_pred))\n",
    "    labels_sorted = [int(x) for x in labels_sorted]  # Convert to regular int for clean display\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels_sorted)\n",
    "\n",
    "    print(f\"\\n=== {fname} ===\")\n",
    "    print(f\"Accuracy: {acc:.6f}\")\n",
    "    print(f\"Macro F1: {macro_f1:.6f}\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"           Predicted\")\n",
    "    print(f\"           \", \" \".join(f\"{lab:>6}\" for lab in labels_sorted))\n",
    "    print(f\"Actual\")\n",
    "    for i, row in enumerate(cm):\n",
    "        print(f\"  {labels_sorted[i]:>6}   {' '.join(f'{val:>6}' for val in row)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNsXT/oPWx6J5ByluOO8NeL",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
